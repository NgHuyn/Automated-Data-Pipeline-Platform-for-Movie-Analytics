{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDataExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize and configure MongoDB connection.\"\"\"\n",
    "        load_dotenv()\n",
    "        self.db = self.connect_to_mongo()\n",
    "\n",
    "    def connect_to_mongo(self):\n",
    "        \"\"\"Connect to MongoDB and return the database object.\"\"\"\n",
    "        client = pymongo.MongoClient(os.getenv('MONGO_URI'))\n",
    "        db_name = os.getenv('MONGODB_DATABASE', 'default_db_name').replace(' ', '_')\n",
    "        return client[db_name]\n",
    "\n",
    "    def load_collection_as_dataframe(self, collection_name):\n",
    "        \"\"\"Load MongoDB collection into a DataFrame.\"\"\"\n",
    "        data = list(self.db[collection_name].find({}))\n",
    "        if not data:\n",
    "            logging.warning(f\"No data found in collection: {collection_name}\")\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def check_and_mark_processed(self, collection):\n",
    "        \"\"\"Check if a collection is processed and mark it if not.\"\"\"\n",
    "        if not self.db['processing_flags'].find_one({'collection': collection}):\n",
    "            self.db['processing_flags'].insert_one({'collection': collection})\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def process_all_collections(self):\n",
    "        \"\"\"Load and transform all specified collections from MongoDB.\"\"\"\n",
    "        \n",
    "        # Function to transform movie reviews DataFrame and map Movie ID to movie_id\n",
    "        def transform_movie_reviews(df, movie_details_df):\n",
    "            \"\"\"Transform movie reviews DataFrame.\"\"\"\n",
    "            required_columns = ['Movie ID', 'Reviews']\n",
    "            \n",
    "            # Check for required columns in the DataFrame\n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            if missing_columns:\n",
    "                logging.error(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "                return None\n",
    "\n",
    "            # Create a mapping from imdb_id to movie_id\n",
    "            imdb_id_to_movie_id = dict(zip(movie_details_df['imdb_id'], movie_details_df['id']))\n",
    "            reviews_data = []  # List to store transformed review data\n",
    "\n",
    "            # Iterate over each row in the DataFrame\n",
    "            for index, row in df.iterrows():\n",
    "                movie_id = row['Movie ID']\n",
    "                reviews = row['Reviews']\n",
    "                mapped_movie_id = imdb_id_to_movie_id.get(movie_id)\n",
    "                \n",
    "                if mapped_movie_id is None:\n",
    "                    logging.warning(f\"Movie ID {movie_id} not found in movie_details.\")\n",
    "                    continue  # Skip if the Movie ID is not found\n",
    "\n",
    "                # Iterate over each review and extract relevant information\n",
    "                for review in reviews:\n",
    "                    reviews_data.append({\n",
    "                        'movie_id': mapped_movie_id,\n",
    "                        'review_summary': review.get('Review Summary'),\n",
    "                        'review_text': review.get('Review'),\n",
    "                        'rating': review.get('Rating'),\n",
    "                        'author': review.get('Author'),\n",
    "                        'date': review.get('Date'),\n",
    "                        'helpful': review.get('Helpful'),\n",
    "                        'not_helpful': review.get('Not Helpful')\n",
    "                    })\n",
    "\n",
    "            return {'review': pd.DataFrame(reviews_data)}  # Return DataFrame of reviews\n",
    "\n",
    "        # Define transformations for each collection\n",
    "        transformations = {\n",
    "            'movie_genres': lambda df: {'genre': df.drop(columns=['_id']).rename(columns={'id': 'genre_id'})} \n",
    "                                        if not self.check_and_mark_processed('movie_genres') else None,\n",
    "            'movie_details': lambda df: {\n",
    "                'movie': df[['id', 'title', 'budget', 'homepage', 'overview', 'popularity', \n",
    "                            'release_date', 'revenue', 'runtime', 'status', 'tagline', \n",
    "                            'vote_average', 'vote_count']].rename(columns={'id': 'movie_id'}).drop_duplicates(),\n",
    "                'movie_genre': pd.DataFrame([(row['id'], g['id']) for _, row in df.iterrows() for g in row['genres']], \n",
    "                                            columns=['movie_id', 'genre_id'])\n",
    "            },\n",
    "            'movie_actor_credits': lambda df: {\n",
    "                'movie_cast': df[['id', 'character', 'order', 'movie_tmdb_id']].rename(columns={'id': 'actor_id', 'order': 'order_num', 'movie_tmdb_id': 'movie_id'}).drop_duplicates()\n",
    "            },\n",
    "            'movie_director_credits': lambda df: {\n",
    "                'movie_direction': df[['id', 'known_for_department', 'movie_tmdb_id']].rename(columns={'id': 'director_id', 'movie_tmdb_id': 'movie_id'}).drop_duplicates()\n",
    "            },\n",
    "            'actor_details': lambda df: {\n",
    "                'actor': df[['id', 'name', 'gender', 'birthday', 'deathday', 'popularity', 'place_of_birth']]\n",
    "                .rename(columns={'id': 'actor_id'})\n",
    "                .replace({'gender': {0: 'Not set / not specified', 1: 'Female', 2: 'Male', 3: 'Non-binary'}})\n",
    "                .replace({np.nan: None})\n",
    "                .drop_duplicates()\n",
    "            },\n",
    "            'director_details': lambda df: {\n",
    "                'director': df[['id', 'name', 'gender', 'birthday', 'deathday', 'popularity', 'place_of_birth']]\n",
    "                .rename(columns={'id': 'director_id'})\n",
    "                .replace({'gender': {0: 'Not set / not specified', 1: 'Female', 2: 'Male', 3: 'Non-binary'}})\n",
    "                .replace({np.nan: None})\n",
    "                .drop_duplicates()\n",
    "            },  \n",
    "            'movie_reviews': lambda df: transform_movie_reviews(df, movie_details_df) \n",
    "        }\n",
    "\n",
    "        transformed_data = {}\n",
    "        # Load movie_details once to use for mapping\n",
    "        movie_details_df = self.load_collection_as_dataframe('movie_details')[['id', 'imdb_id']]\n",
    "\n",
    "        # Process each collection and apply transformations\n",
    "        for collection, transform_func in transformations.items():\n",
    "            df = self.load_collection_as_dataframe(collection)\n",
    "            if not df.empty:\n",
    "                collection_data = transform_func(df)\n",
    "                if collection_data is not None:\n",
    "                    transformed_data.update(collection_data)\n",
    "\n",
    "        # Check and mark processed for movie_genres at the end of processing\n",
    "        self.check_and_mark_processed('movie_genres')\n",
    "\n",
    "        return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No data found in collection: movie_details\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['id', 'imdb_id'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m extractor \u001b[38;5;241m=\u001b[39m MongoDataExtractor()\n\u001b[1;32m----> 2\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_all_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[1;32mIn[205], line 106\u001b[0m, in \u001b[0;36mMongoDataExtractor.process_all_collections\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Load movie_details once to use for mapping\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m movie_details_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_collection_as_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie_details\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimdb_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Process each collection and apply transformations\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collection, transform_func \u001b[38;5;129;01min\u001b[39;00m transformations\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\NH Ngoc Huyen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\NH Ngoc Huyen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NH Ngoc Huyen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['id', 'imdb_id'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "extractor = MongoDataExtractor()\n",
    "transformed_data = extractor.process_all_collections()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for collection: genre, Data shape: (19, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id       name\n",
       "0        28     Action\n",
       "1        12  Adventure\n",
       "2        16  Animation\n",
       "3        35     Comedy\n",
       "4        80      Crime"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      "genre_id     int64\n",
      "name        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "specific_collection = 'genre'\n",
    "\n",
    "if specific_collection in transformed_data:\n",
    "    df = transformed_data[specific_collection]\n",
    "    print(f\"DataFrame for collection: {specific_collection}, Data shape: {df.shape}\")\n",
    "    display(df.head())  \n",
    "    print(\"Data types of each column:\")\n",
    "    print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
